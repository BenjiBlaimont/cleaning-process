{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful Export\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from scipy.stats import poisson\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "# Set Function\n",
    "def dataCleaning(file, name):\n",
    "    # Read File and Convert in DF\n",
    "    df = pd.read_csv(file, delimiter=';')\n",
    "    \n",
    "    if(name == 'ss'):\n",
    "        # Edit Columns\n",
    "        df.columns = [\"BRANCH_ID\",\"PRODUCT_ID\",\"PRODUCT_BRANCH_ID\",\"PRODUCT\",\"AVAILABILITY\",\"LAST_VISITED\"]\n",
    "        df[\"LAST_VISITED\"] = pd.to_datetime(df[\"LAST_VISITED\"],format='%Y-%m-%d')\n",
    "        condition = (df[\"BRANCH_ID\"].notnull())\n",
    "\n",
    "        return df[condition]\n",
    "    \n",
    "    elif(name == 'fr'):\n",
    "        # Edit Columns\n",
    "        df.columns = [\"BRANCH_ID\",\"PRODUCT_ID\",\"PRODUCT_BRANCH_ID\",\"TIMES_FOUND\",\"TIMES_ORDERED\",\"FOUND_RATE\"]\n",
    "        df[\"FOUND_RATE\"] = df[\"FOUND_RATE\"].str.replace(',','.')\n",
    "        df[\"FOUND_RATE\"] = df[\"FOUND_RATE\"].astype(float)\n",
    "        condition = df[\"BRANCH_ID\"].notnull()\n",
    "\n",
    "        return df[condition]\n",
    "\n",
    "    elif(name == 'bk'):\n",
    "\n",
    "        df.columns = [\"PRODUCT_ID\",\"BLOCKING_REASON\",\"PRODUCT_NAME\"]\n",
    "        df[\"PRODUCT_ID\"] = df[\"PRODUCT_ID\"].astype(float)\n",
    "        return df\n",
    "\n",
    "def mergeFiles(ss, fr):\n",
    "        \n",
    "        df      =   pd.merge(ss,fr, on=['BRANCH_ID','PRODUCT_ID','PRODUCT_BRANCH_ID'],how='left')\n",
    "        bkClean =   bk.drop_duplicates('PRODUCT_ID')\n",
    "        df      =   pd.merge(df,bkClean, how = 'left')\n",
    "        return df\n",
    "\n",
    "def cleaningRules(ss, totalDays):\n",
    "        \n",
    "        date = datetime.now() - relativedelta(days=totalDays) \n",
    "\n",
    "        nc_R1 = ss[\n",
    "                (\n",
    "                        (ss['LAST_VISITED'] > date)\n",
    "                    &   (ss['AVAILABILITY'].isin(['AVAILABLE','FREQUENTLY_OUT_OF_STOCK'])) \n",
    "                    &   (ss['BLOCKING_REASON'].isna())  \n",
    "                    &   (ss['FOUND_RATE'] < 0.5)\n",
    "                )\n",
    "        ].count()[0]\n",
    "\n",
    "        nc_R2 = ss[\n",
    "                (\n",
    "                        (ss['LAST_VISITED'] < date)\n",
    "                    &   (ss['AVAILABILITY'].isin(['OUT_OF_STOCK'])) \n",
    "                    &   (ss['BLOCKING_REASON'].isna())  \n",
    "                    &   (ss['FOUND_RATE'] < 0.5)\n",
    "                )\n",
    "        ].count()[0]\n",
    "\n",
    "        nc_R3 = ss[\n",
    "                (\n",
    "                        (ss['LAST_VISITED'] < date)\n",
    "                    &   (ss['AVAILABILITY'].isin(['OUT_OF_STOCK']))  \n",
    "                    &   (ss['FOUND_RATE'] == 1)\n",
    "                )\n",
    "        ].count()[0]\n",
    "\n",
    "        dataAnalysis = {\n",
    "            'Type':[\n",
    "                'NSS',\n",
    "                'NSS',\n",
    "                'NSS',\n",
    "                'NSS'\n",
    "            ],\n",
    "            'Rules Normal Stop Send': [\n",
    "                'Total Stop Send',\n",
    "                'Last visited < 1 mes / Disponible para comprar / Sin bloqueo / FR < 50%: ',\n",
    "                'Last visited > 1 mes / No disponible para comprar / Sin bloqueo / FR < 50%: ',\n",
    "                'Last visited > 1 mes / No disponible para comprar / FR = 100%: '\n",
    "            ],\n",
    "            'Powered Products':[\n",
    "                ss.count()[0],\n",
    "                nc_R1,\n",
    "                nc_R2,\n",
    "                nc_R3\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        dataAnalysis = pd.DataFrame(dataAnalysis)  \n",
    "        \n",
    "        return dataAnalysis \n",
    "        \n",
    "def actionList(ss, storeId, today, totalDays):\n",
    "\n",
    "        date = today - relativedelta(days=totalDays) \n",
    "\n",
    "        actionListOne = ss[\n",
    "                (\n",
    "                        (ss['LAST_VISITED'] > date)\n",
    "                    &   (ss['AVAILABILITY'].isin(['AVAILABLE','FREQUENTLY_OUT_OF_STOCK'])) \n",
    "                    &   (ss['BLOCKING_REASON'].isna())  \n",
    "                    &   (ss['FOUND_RATE'] < 0.5)\n",
    "                )\n",
    "        ]\n",
    "\n",
    "        actionListTwo = ss[\n",
    "                (\n",
    "                        (ss['LAST_VISITED'] < date)\n",
    "                    &   (ss['AVAILABILITY'].isin(['OUT_OF_STOCK'])) \n",
    "                    &   (ss['BLOCKING_REASON'].isna())  \n",
    "                    &   (ss['FOUND_RATE'] < 0.5)\n",
    "                )\n",
    "        ]\n",
    "\n",
    "        actionListThree = ss[\n",
    "                (\n",
    "                        (ss['LAST_VISITED'] < date)\n",
    "                    &   (ss['AVAILABILITY'].isin(['OUT_OF_STOCK']))  \n",
    "                    &   (ss['FOUND_RATE'] == 1)\n",
    "                )\n",
    "        ]\n",
    "\n",
    "\n",
    "        actionListOne   ['AVAILABILITY']    =   'UNAVAILABLE'\n",
    "        actionListTwo   ['AVAILABILITY']    =   'UNAVAILABLE'\n",
    "        actionListThree ['AVAILABILITY']    =   'AVAILABLE'\n",
    "\n",
    "        bulk = pd.concat([actionListOne, actionListTwo, actionListThree], ignore_index=True)\n",
    "\n",
    "        bulk['STORE_ID'] = storeId\n",
    "        bulk['PRICE'] = ''\n",
    "        bulk['SCHEDULE'] = ''\n",
    "\n",
    "        columns = ['STORE_ID','PRODUCT_BRANCH_ID', 'PRICE', 'AVAILABILITY', 'SCHEDULE']\n",
    "\n",
    "        bulk = bulk[columns]\n",
    "        bulk.columns = bulk.columns.str.lower()\n",
    "\n",
    "        \n",
    "        # bulk.columns = ['store_id', 'product_branch_id','price','availability','schedule']\n",
    "\n",
    "        return bulk\n",
    "\n",
    "def overview(ss,today, days):\n",
    "\n",
    "    date = today - relativedelta(days=days) \n",
    "\n",
    "    m1  =   ss[ss['AVAILABILITY'].isin(['AVAILABLE','FREQUENTLY_OUT_OF_STOCK'])].count()[0]\n",
    "\n",
    "    m2  =   ss[ss['AVAILABILITY'].isin(['OUT_OF_STOCK'])].count()[0]\n",
    "\n",
    "    m3  =   ss[ss['TIMES_FOUND'].notna()].count()[0]\n",
    "\n",
    "    m4  =   ss[ss['TIMES_FOUND'].isna()].count()[0]\n",
    "\n",
    "    m5  =   ss[ss['FOUND_RATE'] < 0.5].count()[0]\n",
    "\n",
    "    m6  =   ss[ss['FOUND_RATE'] > 0.5].count()[0]\n",
    "\n",
    "    m7  =   ss[ss['LAST_VISITED'] > date].count()[0]\n",
    "\n",
    "    m8  =   ss[ss['LAST_VISITED'] < date].count()[0]\n",
    "\n",
    "    m9  =   ss[ss['BLOCKING_REASON']   == 'AON'].count()[0]\n",
    "\n",
    "    m10 =   ss[     (ss['BLOCKING_REASON']  == 'Tiene 2 SKU') \n",
    "                |   (ss['BLOCKING_REASON']  == 'Tiene 3 SKU')\n",
    "                |   (ss['BLOCKING_REASON']  == 'Tiene 4 SKU')\n",
    "            ].count()[0]\n",
    "\n",
    "    m11 =   ss[     (ss['BLOCKING_REASON']  == 'Brands') \n",
    "                |   (ss['BLOCKING_REASON']  == 'Brands In&out')\n",
    "            ].count()[0]\n",
    "\n",
    "    m12 =   ss[     (ss['BLOCKING_REASON']  == 'Sin integración') ].count()[0]\n",
    "\n",
    "    overviewData = {\n",
    "        'Review':[\n",
    "            'Disponibles para comprar (AV/FOOS)',\n",
    "            'No disponibles para comprar (OOS)',\n",
    "            'Con ventas',\n",
    "            'Sin ventas',\n",
    "            'Found Rate < 50%',\n",
    "            'Found Rate > 50%',\n",
    "            'Con antigüedad < 1 mes',\n",
    "            'Con antigüedad > 1 mes',\n",
    "            'Con bloqueo AON',\n",
    "            'Con bloqueo más de 1 sku',\n",
    "            'Con bloqueo brands',\n",
    "            'Sin integración',\n",
    "        ],\n",
    "        '# PbId':[\n",
    "            m1,\n",
    "            m2,\n",
    "            m3,\n",
    "            m4,\n",
    "            m5,\n",
    "            m6,\n",
    "            m7,\n",
    "            m8,\n",
    "            m9,\n",
    "            m10,\n",
    "            m11,\n",
    "            m12\n",
    "        ],\n",
    "        '% PbId':[\n",
    "            (m1 / ss.count()[0]) * 100,\n",
    "            (m2 / ss.count()[0]) * 100,\n",
    "            (m3 / ss.count()[0]) * 100,\n",
    "            (m4 / ss.count()[0]) * 100,\n",
    "            (m5 / ss.count()[0]) * 100,\n",
    "            (m6 / ss.count()[0]) * 100,\n",
    "            (m7 / ss.count()[0]) * 100,\n",
    "            (m8 / ss.count()[0]) * 100,\n",
    "            (m9 / ss.count()[0]) * 100,\n",
    "            (m10 / ss.count()[0]) * 100,\n",
    "            (m11 / ss.count()[0]) * 100,\n",
    "            (m12 / ss.count()[0]) * 100\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    overview = pd.DataFrame(overviewData) \n",
    "    overview = overview.round({'% PbId': 2})\n",
    "\n",
    "    overview['% PbId'] = [ \"{}%\".format(v) for v in overview['% PbId'] ]\n",
    "\n",
    "    return overview\n",
    "\n",
    "\n",
    "storeId     =   4\n",
    "week        =   '17'\n",
    "cleaning    =   '02'\n",
    "days        =   32\n",
    "\n",
    "today = datetime.now()\n",
    "\n",
    "ssFile = 'FILES/W'+week+'/'+cleaning+'_SS_W'+week+'.csv'\n",
    "frFile = 'FILES/W'+week+'/'+cleaning+'_FR_W'+week+'.csv'\n",
    "bkFile = 'FILES/W'+week+'/'+cleaning+'_BQ_W'+week+'.csv'\n",
    "\n",
    "ss  =   dataCleaning(ssFile, 'ss' )\n",
    "fr  =   dataCleaning(frFile, 'fr' )\n",
    "bk  =   dataCleaning(bkFile, 'bk' )\n",
    "\n",
    "\n",
    "ssM     =   mergeFiles(ss,fr)\n",
    "\n",
    "ssResults   =   cleaningRules(ssM, days)\n",
    "bulk        =   actionList(ssM,storeId, today, days)\n",
    "overview = overview(ssM, today, days)\n",
    "\n",
    "\n",
    "\n",
    "today = str(datetime.today().strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "fr\n",
    "\n",
    "# START EXPORT FILES\n",
    "\n",
    "bulk.to_excel('FILES/W'+week+'/'+today+'_BULK_JUMBO_CLEANING.xlsx', index=False) # FILE TO UPLOAD TO THE BULK\n",
    "\n",
    "analysis = pd.ExcelWriter('FILES/W'+week+'/'+today+'_ANALYSIS_STOP_SEND_JUMBO.xlsx', engine='xlsxwriter') # CREATE MULTI SHEETS FILES\n",
    "\n",
    "overview.to_excel(analysis, sheet_name='OVERVIEW',index=False)              # CREATE OVERVIEW SHEET\n",
    "ssResults.to_excel(analysis, sheet_name='TOTAL ACTIONABLES',index=False)    # CREATE TOTAL ACTIONABLES SHEET\n",
    "bulk.to_excel(analysis, sheet_name='POWERED PRODUCTBRANCHS',index=False)    # CREATE POWERED PRODUCTBRANCHS SHEET\n",
    "ssM.to_excel(analysis, sheet_name='FULL FILE',index=False)     # CREATE POWERED PRODUCTBRANCHS SHEET\n",
    "analysis.save() # SAVE MULTI SHEET FILE CHANGES\n",
    "\n",
    "print('Successful Export')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20cd134fc601216ffcf3f697934235fd20914a27a46a8a648c0d662d717ffa47"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
